# PRISM - Predictive Risk Intelligence for Software Management

**A Hybrid AI System Integrating Machine Learning and Large Language Models for Software Project Risk Analysis**

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://img.shields.io/badge/tests-88%20passed-brightgreen.svg)]()
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Status: Implementation Complete](https://img.shields.io/badge/Status-Implementation%20Complete-success.svg)]()

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [System Architecture](#system-architecture)
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Data Sources](#data-sources)
- [Use Cases](#use-cases)
- [Technology Stack](#technology-stack)
- [Testing](#testing)
- [Documentation](#documentation)
- [License](#license)

---

## ğŸ¯ Overview

PRISM (Predictive Risk Intelligence for Software Management) is an AI-powered system designed to help project managers identify and prioritize software project risks before they escalate into crises. Unlike traditional project management tools that only report current status, PRISM predicts future problems using a unique hybrid approach that combines:

- **Machine Learning (ML):** Analyzes structured project data (budgets, schedules, team metrics) to predict risk scores
- **Large Language Models (LLM):** Evaluates project comments and communications to extract risk indicators and sentiment
- **Multi-Criteria Decision Analysis (MCDA):** Ranks projects based on combined insights from ML, LLM, and performance factors

### The Problem

Software projects face alarmingly high failure rates:
- Only 29% succeed (on time, on budget, with required features)
- 52% are challenged (late, over budget, or missing features)
- 19% fail outright

Traditional risk management is reactiveâ€”problems are identified only after they appear in metrics. Project managers need predictive capabilities that forecast risks 2-4 weeks in advance.

### The Solution

PRISM provides:
- âœ… **Early Risk Detection:** Predicts high-risk projects before traditional metrics deteriorate
- âœ… **Hybrid Intelligence:** Combines quantitative metrics with qualitative team communications
- âœ… **Portfolio Prioritization:** Objectively ranks projects to focus manager attention
- âœ… **Explainable AI:** Natural language explanations via chat assistant
- âœ… **Actionable Insights:** Not just "what" but "why" and "what to do"

---

## âœ¨ Key Features

### 1. Machine Learning Risk Prediction
- **Ensemble models** (Random Forest, XGBoost) for risk classification
- **Feature engineering** from schedule performance, cost variance, velocity, and team metrics
- **SHAP explainability** showing which factors drive each project's risk score
- **Cross-validation** and hyperparameter tuning support

### 2. LLM-Powered Text Analysis
- **OpenAI GPT integration** to analyze project comments, status updates, team feedback
- **Risk extraction:** Identifies concerns, blockers, and warning signs in natural language
- **Sentiment analysis:** Detects team morale issues and stakeholder dissatisfaction
- **Risk categorization:** Technical, resource, schedule, and scope risks

### 3. MCDA Project Ranking
- **TOPSIS algorithm** ranks projects based on multiple weighted criteria:
  - ML risk score (40% weight)
  - LLM sentiment score (25%)
  - Schedule performance index (15%)
  - Cost performance index (10%)
  - Team stability (10%)
- **Configurable weights** via YAML configuration
- **Sensitivity analysis** validates ranking stability

### 4. Interactive Dashboard
- **Streamlit-based** web interface
- **File upload:** CSV/JSON from Jira, Azure DevOps, Monday.com, etc.
- **Visualizations:** Risk distribution charts, trend analysis, project comparisons
- **Export functionality:** Reports and data export

### 5. AI Chat Assistant
- **Natural language Q&A:** Ask questions about specific projects
- **Risk explanations:** "Why is Project X high risk?"
- **Recommendations:** Context-aware suggestions based on analysis results
- **Conversation memory:** Multi-turn dialogues

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PRISM Dashboard                          â”‚
â”‚                      (Streamlit Interface)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚Dashboardâ”‚  â”‚ ML       â”‚  â”‚   LLM   â”‚  â”‚MCDA  â”‚  â”‚  Chat  â”‚ â”‚
â”‚  â”‚Overview â”‚  â”‚ Analysis â”‚  â”‚Insights â”‚  â”‚Ranks â”‚  â”‚Assist. â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Core Processing Modules                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ML Module       â”‚   LLM Module       â”‚   MCDA Module            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚Random Forest â”‚ â”‚ â”‚OpenAI GPT API  â”‚ â”‚ â”‚TOPSIS Ranking        â”‚ â”‚
â”‚ â”‚XGBoost       â”‚ â”‚ â”‚Risk Extraction â”‚ â”‚ â”‚Criteria Weighting    â”‚ â”‚
â”‚ â”‚SHAP Explainerâ”‚ â”‚ â”‚Sentiment Score â”‚ â”‚ â”‚Sensitivity Analysis  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Data Processing & Feature Engineering               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Data      â”‚  â”‚Validation â”‚  â”‚Feature   â”‚  â”‚Preprocessing â”‚  â”‚
â”‚  â”‚Loader    â”‚  â”‚& Cleaning â”‚  â”‚Engineer  â”‚  â”‚Pipeline      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
prism/
â”œâ”€â”€ app/                          # Streamlit application
â”‚   â”œâ”€â”€ app.py                    # Main entry point
â”‚   â””â”€â”€ pages/                    # Dashboard pages
â”‚       â”œâ”€â”€ 1_ğŸ“Š_Dashboard.py
â”‚       â”œâ”€â”€ 2_ğŸ“_Upload_Data.py
â”‚       â”œâ”€â”€ 3_ğŸ¤–_ML_Analysis.py
â”‚       â”œâ”€â”€ 4_ğŸ’¬_LLM_Insights.py
â”‚       â”œâ”€â”€ 5_ğŸ“ˆ_Rankings.py
â”‚       â”œâ”€â”€ 6_ğŸ”_Compare_Projects.py
â”‚       â””â”€â”€ 7_ğŸ’­_Chat_Assistant.py
â”‚
â”œâ”€â”€ src/                          # Core source code
â”‚   â”œâ”€â”€ data/                     # Data processing modules
â”‚   â”‚   â”œâ”€â”€ loader.py             # Data loading (CSV, JSON, Excel)
â”‚   â”‚   â”œâ”€â”€ validator.py          # Data validation
â”‚   â”‚   â”œâ”€â”€ preprocessor.py       # Preprocessing pipeline
â”‚   â”‚   â”œâ”€â”€ feature_engineer.py   # Feature creation
â”‚   â”‚   â””â”€â”€ generator.py          # Synthetic data (for testing)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                   # ML and LLM models
â”‚   â”‚   â”œâ”€â”€ ml/                   # Machine learning
â”‚   â”‚   â”‚   â”œâ”€â”€ trainer.py        # Model training
â”‚   â”‚   â”‚   â”œâ”€â”€ predictor.py      # Predictions
â”‚   â”‚   â”‚   â””â”€â”€ evaluator.py      # Model evaluation
â”‚   â”‚   â””â”€â”€ llm/                  # Large language models
â”‚   â”‚       â”œâ”€â”€ analyzer.py       # LLM text analysis
â”‚   â”‚       â””â”€â”€ risk_extractor.py # Risk extraction
â”‚   â”‚
â”‚   â”œâ”€â”€ mcda/                     # Multi-criteria decision analysis
â”‚   â”‚   â”œâ”€â”€ topsis.py             # TOPSIS algorithm
â”‚   â”‚   â””â”€â”€ ranker.py             # Project ranking
â”‚   â”‚
â”‚   â”œâ”€â”€ explainability/           # Model interpretation
â”‚   â”‚   â””â”€â”€ shap_explainer.py     # SHAP explanations
â”‚   â”‚
â”‚   â”œâ”€â”€ chat/                     # Chat assistant
â”‚   â”‚   â””â”€â”€ assistant.py          # Conversational AI
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/            # Charts and visualizations
â”‚   â”‚   â””â”€â”€ risk_charts.py        # Plotly charts
â”‚   â”‚
â”‚   â””â”€â”€ utils/                    # Utilities
â”‚       â”œâ”€â”€ logger.py             # Logging configuration
â”‚       â””â”€â”€ metrics.py            # Portfolio metrics
â”‚
â”œâ”€â”€ config/                       # Configuration files
â”‚   â”œâ”€â”€ settings.py               # Application settings
â”‚   â”œâ”€â”€ mcda_config.yaml          # MCDA weights
â”‚   â”œâ”€â”€ model_config.yaml         # ML model parameters
â”‚   â””â”€â”€ llm_config.yaml           # LLM settings
â”‚
â”œâ”€â”€ data/                         # Data directory
â”‚   â”œâ”€â”€ raw/                      # Raw project data files
â”‚   â”œâ”€â”€ processed/                # Processed data
â”‚   â””â”€â”€ schemas/                  # Validation schemas
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ unit/                     # Unit tests
â”‚   â””â”€â”€ integration/              # Integration tests
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ preprocess_jira_data.py   # Jira data preprocessing
â”‚   â””â”€â”€ train_models.py           # Model training script
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â””â”€â”€ academic/                 # Academic chapters
â”‚
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ pyproject.toml                # Project configuration
â”œâ”€â”€ Makefile                      # Build commands
â””â”€â”€ README.md                     # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10 or higher
- pip package manager
- OpenAI API key ([get one here](https://platform.openai.com/api-keys)) - for LLM features
- macOS users: `brew install libomp` (for XGBoost support)

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/prism.git
cd prism

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure environment (optional, for LLM features)
cp env_template.txt .env
# Edit .env and add your OPENAI_API_KEY=sk-...

# 5. Run tests to verify installation
pytest tests/

# 6. Launch dashboard
streamlit run app/app.py
```

### First-Time Usage

1. **Open your browser** to `http://localhost:8501`
2. **Click "Load Sample Data"** on the home page (or upload your own CSV)
3. **Navigate to different pages** to explore ML Analysis, LLM Insights, Rankings
4. **Use the Chat Assistant** to ask questions about your projects

---

## ğŸ“¦ Data Sources

### Project Data Location

Real project data should be placed in `data/raw/`. The system supports:

- **CSV files** - Recommended format
- **JSON files** - For structured data
- **Excel files** - .xlsx format

### Required Fields

| Field | Type | Description |
|-------|------|-------------|
| `project_id` | Text | Unique identifier |
| `project_name` | Text | Project name |
| `start_date` | Date | Start date (YYYY-MM-DD) |
| `planned_end_date` | Date | Target end date |
| `budget` | Number | Total budget |
| `spent` | Number | Current spend |
| `planned_hours` | Number | Estimated hours |
| `actual_hours` | Number | Logged hours |
| `team_size` | Number | Team members |
| `completion_rate` | Number | Percent complete (0-100) |
| `status` | Text | Current status |
| `status_comments` | Text | Project updates (for LLM analysis) |

### Jira Data Integration

Use the preprocessing script to convert Jira exports:

```bash
# Process Jira data export
python scripts/preprocess_jira_data.py --input data/raw/jira_export.csv

# Process specific projects
python scripts/preprocess_jira_data.py --projects SPARK,KAFKA,FLINK
```

---

## ğŸ’¼ Use Cases

### Portfolio Health Check
Upload all project data, view risk distribution, identify top concerns, and generate reports for stakeholder meetings.

### Single Project Deep-Dive
Analyze a specific project to understand risk drivers through ML feature importance and LLM-extracted concerns from team comments.

### Trend Analysis
Compare multiple time periods to assess if portfolio health is improving or degrading over time.

See [USER_APPLICATION_GUIDE.md](USER_APPLICATION_GUIDE.md) for detailed workflows and examples.

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Language** | Python 3.10+ | Core development |
| **ML Framework** | scikit-learn, XGBoost | Model training and prediction |
| **Interpretability** | SHAP | Model explanations |
| **LLM API** | OpenAI GPT | Text analysis |
| **MCDA** | Custom TOPSIS | Project ranking |
| **Dashboard** | Streamlit | Web interface |
| **Visualization** | Plotly | Interactive charts |
| **Data** | pandas, numpy | Data manipulation |
| **Testing** | pytest | Test framework |
| **Logging** | loguru | Application logging |

---

## ğŸ§ª Testing

The project includes comprehensive tests:

```bash
# Run all tests
pytest tests/

# Run with verbose output
pytest tests/ -v

# Run specific test file
pytest tests/unit/test_mcda.py

# Run with coverage
pytest tests/ --cov=src
```

**Current Status:** 88 tests passing, 6 skipped (XGBoost environment dependency)

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [USER_APPLICATION_GUIDE.md](USER_APPLICATION_GUIDE.md) | Complete user manual with workflows |
| [PROJECT_STRATEGY.md](PROJECT_STRATEGY.md) | Implementation strategy and planning |
| [DELIVERABLES_SUMMARY.md](DELIVERABLES_SUMMARY.md) | Project deliverables overview |
| [docs/academic/](docs/academic/) | Academic chapters and citations |
| [data/README.md](data/README.md) | Data schema and preparation guide |

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- OpenAI for GPT API
- scikit-learn and XGBoost communities
- Streamlit for the dashboard framework
- SHAP library for model interpretability

---

<div align="center">

**Built with Python, scikit-learn, OpenAI GPT, and Streamlit**

*Transforming software project management from reactive to predictive*

</div>
